import pandas as pd
import numpy as np
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, f1_score, roc_auc_score, precision_score, recall_score
import warnings

warnings.filterwarnings('ignore')

print("üöÄ –ó–ê–ü–£–°–ö –†–ï–ñ–ò–ú–ê 'ULTRA' (TARGET ENCODING + AGGREGATIONS)...")

# --- 1. –ó–ê–ì–†–£–ó–ö–ê ---
df_trans = pd.read_csv('data/—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏_–≤_–ú–æ–±–∏–ª—å–Ω–æ–º_–∏–Ω—Ç–µ—Ä–Ω–µ—Ç_–ë–∞–Ω–∫–∏–Ω–≥–µ.csv', sep=';', header=1, encoding='cp1251')
df_behav = pd.read_csv('data/–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ_–ø–∞—Ç—Ç–µ—Ä–Ω—ã_–∫–ª–∏–µ–Ω—Ç–æ–≤_3.csv', sep=';', header=1, encoding='cp1251')

# –ß–∏—Å—Ç–∫–∞
for df in [df_trans, df_behav]:
    df['transdate'] = pd.to_datetime(df['transdate'].str.strip("'"))
df_trans['transdatetime'] = pd.to_datetime(df_trans['transdatetime'].str.strip("'"))

# –ú–µ—Ä–∂
df = pd.merge(df_trans, df_behav, on=['cst_dim_id', 'transdate'], how='left')

# --- 2. FEATURE ENGINEERING (PRO LEVEL) ---

# 2.1. –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
df['hour'] = df['transdatetime'].dt.hour
df['day_of_week'] = df['transdatetime'].dt.dayofweek
df['is_night'] = df['hour'].apply(lambda x: 1 if x < 6 or x > 23 else 0)

# 2.2. TARGET ENCODING –¥–ª—è Direction (–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞ –ø–æ–ª—É—á–∞—Ç–µ–ª—è)
# –°—É—Ç—å: –°—á–∏—Ç–∞–µ–º % —Ñ—Ä–æ–¥–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è, –Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º "–≤–µ—Å –¥–æ–≤–µ—Ä–∏—è" (Smoothing),
# —á—Ç–æ–±—ã –Ω–µ –±–∞–Ω–∏—Ç—å –ø–æ–ª—É—á–∞—Ç–µ–ª—è —Å 1 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–µ–π.
def smooth_target_encode(df, cat_col, target_col, weight=10):
    # –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ñ—Ä–æ–¥–∞ –ø–æ –≤—Å–µ–π –±–∞–∑–µ)
    global_mean = df[target_col].mean()
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    agg = df.groupby(cat_col)[target_col].agg(['count', 'mean'])
    counts = agg['count']
    means = agg['mean']
    
    # –§–æ—Ä–º—É–ª–∞ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è: (count * mean + weight * global_mean) / (count + weight)
    smoothed = (counts * means + weight * global_mean) / (counts + weight)
    
    return df[cat_col].map(smoothed).fillna(global_mean)

# –í–ê–ñ–ù–û: –°—á–∏—Ç–∞–µ–º —ç—Ç–æ –¢–û–õ–¨–ö–û –Ω–∞ Train —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —É—Ç–µ—á–∫–∏!
# –ù–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∑–¥–µ—Å—å —Ä–∞–∑–¥–µ–ª–∏–º –≤—ã–±–æ—Ä–∫—É –î–û –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏—á–µ–π
X_temp = df.drop(columns=['target'])
y_temp = df['target']
X_train_idx, X_test_idx = train_test_split(df.index, test_size=0.2, random_state=42, stratify=y_temp)

# –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)
df['receiver_risk_score'] = df['target'].mean()

# –û–±—É—á–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ TRAIN –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ TRAIN
train_df = df.loc[X_train_idx]
df.loc[X_train_idx, 'receiver_risk_score'] = smooth_target_encode(train_df, 'direction', 'target', weight=10)

# –ü—Ä–∏–º–µ–Ω—è–µ–º "–∑–Ω–∞–Ω–∏—è" –∏–∑ TRAIN –∫ TEST (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏)
# –ë–µ—Ä–µ–º —Å–ª–æ–≤–∞—Ä—å —Ä–∏—Å–∫–æ–≤ –∏–∑ —Ç—Ä–µ–π–Ω–∞
risk_map = df.loc[X_train_idx].groupby('direction')['receiver_risk_score'].mean()
global_risk = df.loc[X_train_idx]['target'].mean()
# –ú–∞–ø–∏–º, –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ (–Ω–æ–≤—ã–π –ø–æ–ª—É—á–∞—Ç–µ–ª—å) ‚Äî —Å—Ç–∞–≤–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫
df.loc[X_test_idx, 'receiver_risk_score'] = df.loc[X_test_idx, 'direction'].map(risk_map).fillna(global_risk)


# 2.3. USER AGGREGATIONS (–ö–æ–Ω—Ç–µ–∫—Å—Ç –∫–ª–∏–µ–Ω—Ç–∞)
# –ù–∞—Å–∫–æ–ª—å–∫–æ —ç—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –±–æ–ª—å—à–µ –æ–±—ã—á–Ω–æ–π –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞?
# (–í —Ä–µ–∞–ª–µ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –æ–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç—É—Ç —É–ø—Ä–æ—Å—Ç–∏–º –¥–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏)
user_stats = df.groupby('cst_dim_id')['amount'].agg(['mean', 'std']).reset_index()
user_stats.columns = ['cst_dim_id', 'user_mean_amt', 'user_std_amt']

df = pd.merge(df, user_stats, on='cst_dim_id', how='left')

# Z-score —Å—É–º–º—ã (–Ω–∞—Å–∫–æ–ª—å–∫–æ —Å—É–º–º–∞ –∞–Ω–æ–º–∞–ª—å–Ω–∞ –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞)
# +0.01 —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ –Ω–æ–ª—å
df['amount_zscore'] = (df['amount'] - df['user_mean_amt']) / (df['user_std_amt'] + 0.01)
df['amount_to_mean'] = df['amount'] / (df['user_mean_amt'] + 1.0)

# --- 3. –ü–û–î–ì–û–¢–û–í–ö–ê ---
# –£–±–∏—Ä–∞–µ–º —Å—ã—Ä—ã–µ ID, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞—à–∏ –ù–û–í–´–ï —É–º–Ω—ã–µ —Ñ–∏—á–∏
drop_cols = ['cst_dim_id', 'transdate', 'transdatetime', 'docno', 'direction', 'target', 
             '–ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—É—á–∞—Ç–µ–ª—è/destination —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏',
             'user_mean_amt', 'user_std_amt'] # –£–±–∏—Ä–∞–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º zscore

X = df.drop(columns=[c for c in drop_cols if c in df.columns])
y = df['target']

# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
for col in X.columns:
    if X[col].dtype == 'object':
        X[col] = X[col].fillna('Unknown')
    else:
        X[col] = X[col].fillna(0)

# –ò–Ω–¥–µ–∫—Å—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
cat_features = [i for i, col in enumerate(X.columns) if X[col].dtype == 'object']

# –°–ø–ª–∏—Ç (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –∏–Ω–¥–µ–∫—Å—ã, —á—Ç–æ –∏ –¥–ª—è —ç–Ω–∫–æ–¥–∏–Ω–≥–∞)
X_train = X.loc[X_train_idx]
y_train = y.loc[X_train_idx]
X_test = X.loc[X_test_idx]
y_test = y.loc[X_test_idx]

# --- 4. –û–ë–£–ß–ï–ù–ò–ï (F1 Optimization) ---
print("üî• Training CatBoost (F1 Optimized)...")

# auto_class_weights='SqrtBalanced' ‚Äî —ç—Ç–æ –º—è–≥—á–µ, —á–µ–º Balanced, –Ω–æ –∂–µ—Å—Ç—á–µ, —á–µ–º None.
# –≠—Ç–æ —á–∞—Å—Ç–æ –¥–∞–µ—Ç –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å P/R.
model = CatBoostClassifier(
    iterations=2000,
    learning_rate=0.02,
    depth=6,
    l2_leaf_reg=5,
    auto_class_weights='SqrtBalanced', # –ü–û–ü–†–û–ë–£–ô –≠–¢–û!
    cat_features=cat_features,
    verbose=200,
    random_seed=42,
    early_stopping_rounds=200
)

model.fit(X_train, y_train, eval_set=(X_test, y_test))

# --- 5. –ü–û–ò–°–ö –ò–î–ï–ê–õ–¨–ù–û–ì–û –ü–û–†–û–ì–ê (–ü–û F1) ---
y_prob = model.predict_proba(X_test)[:, 1]

best_thr = 0.5
best_f1 = 0
best_metrics = {}

# –ò—â–µ–º –ø–æ—Ä–æ–≥, –≥–¥–µ F1 (–≥–∞—Ä–º–æ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –ø–æ–ª–Ω–æ—Ç—ã) –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞
for thr in np.arange(0.1, 0.9, 0.01):
    pred = (y_prob > thr).astype(int)
    f1 = f1_score(y_test, pred)
    if f1 > best_f1:
        best_f1 = f1
        best_thr = thr
        best_metrics = {
            'Precision': precision_score(y_test, pred),
            'Recall': recall_score(y_test, pred)
        }

print(f"\nüèÜ OPTIMAL THRESHOLD: {best_thr:.2f}")
print(f"F1-Score:  {best_f1:.2%}")
print(f"Precision: {best_metrics['Precision']:.2%}")
print(f"Recall:    {best_metrics['Recall']:.2%}")

# --- 6. –û–¢–ß–ï–¢ ---
final_pred = (y_prob > best_thr).astype(int)
print("\n--- Final Classification Report ---")
print(classification_report(y_test, final_pred))

imp = model.get_feature_importance(prettified=True).head(7)
print("\nTop Features (Check 'receiver_risk_score' and 'amount_zscore'):")
print(imp)

# Save the model
model.save_model('catboost_model_ultra.cbm')
print("\nüíæ Model saved to 'catboost_model_ultra.cbm'")